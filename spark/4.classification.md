### 파일 불러오기
- 파일 불러오기
```python
%pyspark

file_path = 'hdfs://localhost:9000/input/fish.csv'
df = spark.read.csv(file_path, header=True, inferSchema=True)
```

## 물고기가 Bream인지 Smelt인지 구분
### 로지스틱 회귀분석
- 필요한 데이터 선택
```python
%pyspark
# pecies가 Bream이거나 Smelt인 데이터만 선택
from pyspark.sql.functions import col

df = df.filter(col('species').isin('Bream', 'Smelt'))
```

- 이진분류 → Bream이면 1, 아니면(Smelt) 0
```python
%pyspark
# Bream이면 1, 아니면(Smelt) 0으로 한 데이터를 species_idx에 저장
from pyspark.sql.functions import when
from pyspark.sql.functions import col

df = df.withColumn(
    'species_idx',
    when(col('Species') == 'Bream', 1)
    .otherwise(0)
    )
```

- 예측에 필요한 변수들을 하나의 벡터로 만들기
```python
%pyspark
from pyspark.ml.feature import VectorAssembler

assembler = VectorAssembler(
    inputCols=['Weight', 'Length1', 'Length2', 'Length3', 'Height', 'Width'],
    outputCol='features'
    )
df = assembler.transform(df)
```

- 데이터 분리
```python
%pyspark
train_data, test_data = df.randomSplit([0.8, 0.2])
```

- train_data 학습
```python
%pyspark
from pyspark.ml.classification import LogisticRegression

lr = LogisticRegression(featuresCol='features', labelCol='species_idx')
lr_model = lr.fit(train_data)
```

- test_data 예측
```python
%pyspark
# 예측
prediction = rf_model.transform(test_data)
prediction.show()
```

- 모델 평가
```python
%pyspark
from pyspark.ml.evaluation import BinaryClassificationEvaluator

evaluator = BinaryClassificationEvaluator(labelCol='species_idx', rawPredictionCol='rawPrediction', metricName='areaUnderROC')
result = evaluator.evaluate(prediction)
print(result)
```

### 랜덤포레스트
- train_data 학습
```python
%pyspark
from pyspark.ml.classification import RandomForestClassifier

rf = RandomForestClassifier(featuresCol='features', labelCol='species_idx', maxBins=500)
rf_model = rf.fit(train_data)
```

- test_data 예측
```python
%pyspark
prediction = rf_model.transform(test_data)

prediction.show()
```