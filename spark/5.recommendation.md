### 파일 불러오기
```python
%pyspark
base_path = 'hdfs://localhost:9000/input/netflix/'

movie_data = spark.read.csv(base_path + 'Movie.csv', header=True, inferSchema=True)
rating_data = spark.read.csv(base_path + 'Rating.csv', header=True, inferSchema=True)
```

# ALS
- 협업필터링 기법 중 하나
- 행렬 분해 방식의 추천 알고리즘

- 모델 생성
    - `coldStart` : 훈련 데이터에 존재하지 않는 사용자나 아이템에 대해 모델이 평점을 예측할 수 없는 상황
    - `coldStartStrategy='drop'` : 결측값이 있으면 제거
```python
%pyspark
from pyspark.ml.recommendation import ALS
als = ALS(userCol='User_ID', itemCol='Movie_ID', ratingCol='Rating', coldStartStrategy='drop')
```

- 데이터 분리
```python
%pyspark
train_data, test_data = rating_data.randomSplit([0.8, 0.2])
```

- train_data 학습
```python
%pyspark
als_model = als.fit(train_data)
```

- test_data 예측
```python
%pyspark
prediction = als_model.transform(test_data)
```

### 사용자별 리뷰를 남긴 개수
```python
%pyspark
user_review_count = rating_data.groupBy('User_ID').count()
user_review_count.show()
```

## 1. 사용자에게 영화 추천
### 리뷰를 많이 남긴 사용자 top 5
```python
%pyspark
top_5_users = user_review_count.orderBy('count', ascending=False).limit(5)
top_5_users.show()
```

### 리뷰를 많이 남긴 사용자 top5에게 3개의 영화 추천
- 사용자가 추천할 해당 영화를 본다면 평점을 몇 점 남길지 예측한 후 상위 3개를 추천
```python
%pyspark
# recommendForUserSubset(subset, n) : 사용자의 부분집합(리뷰top5(subset))에 n개의 영화추천

usersubset = top_5_users.select('User_ID')
recommend = als_model.recommendForUserSubset(usersubset, 3)
# truncate=False : 축약하지 않고 출력
recommend.show(truncate=False)
```

### 리뷰를 많이 남긴 사용자 top5별 평균 평점
- `rating_data`와 `top_5_users`테이블 조인
```python
%pyspark
top_5_reviews = rating_data.join(top_5_users, on='User_ID')
top_5_reviews.show()
```
- 사용자별 평균 평점
```python
%pyspark
from pyspark.sql.functions import avg

top_5_reviews.groupBy('User_ID').agg(avg('Rating')).show()
```