# 검색 시스템 이해하기
## 1.1 검색 시스템의 이해
### 1.1.1 검색 시스템이란?
- **검색엔진(search engine)** : 광활한 웹에서 정보를 수집해 검색 결과를 제공하는 프로그램
    - 야후(Yahoo) : 디렉터리 기반의 검색 결과를 세계 최초로 제공

- **검색 시스템(search system)** : 대용량 데이터를 기반으로 신뢰성 있는 검색 결과를 제공하기 위해 검색엔진을 기반으로 구축된 시스템을 통칭하는 용어

- **검색 서비스(search service)** : 검색엔진을 기반으로 구축한 검색 시스템을 활용해 검색 결과를 서비스로 제공

### 1.1.2 검색 시스템의 구성요소
1. **수집기**
    - 웹사이트, 블로그, 카페 등 웹에서 필요한 정보를 수집하는 프로그램
    - 크롤러(Crawler), 스파이더(Spider), 웜(Worms), 웹 로봇(Web Robot) 등으로 불림
    - 수집대상 : 파일, 데이터베이스, 웹페이지 등 웹상의 대부분의 정보

2. **스토리지**
    - 데이터베이스에서 데이터를 저장하는 물리적인 저장소
    - 검색엔진은 색인한 데이를 스토리지에 보관

3. **색인기**
    - 수집된 데이터를 검색 가능한 구조로 가공하고 저장
        
        → 검색엔진이 수집한 정보에서 사용자 질의와 일치하는 정보를 찾기 위해
        
    - 다양한 형태소 분석기 조합 → 의미가 있는 용어 추출 → 검색에 유리한 역색인 구조로 데이터 저장

4. **검색기**
    - 사용자 질의를 입력받아 색인기에서 저장한 역색인 구조에서 일치하는 문서를 찾아 결과로 반환
    - 형태소 분석기를 통해 사용자 질의에서 유의미한 용어를 추출해 검색\
        → 사용하는 형태소 분석기에 따라 검색 품질이 달라짐\
⇒ **수집기 → 색인기 → 스토리지 → 검색기**

### 1.1.3 관계형 데이터베이스와의 차이점
- 데이터베이스 : 데이터를 통합 관리하는 데이터의 집합
    - 중복 제거, 정형 데이터로 구조화해 행과 열로 구성된 테이블에 저장
    - 텍스트를 여러 단어로 변형하거나 여러개의 동의어나 유의어를 활용한 검색은 불가능

- 검색엔진 : 데이터베이스에서는 불가능한 비정형 데이터를 색인하고 검색 가능\
    → 구조화되지 않은 데이터까지 스스로 분석해 자동으로 필드 생성하고 저장
    - 형태소 분석을 통해 사람이 구사하는 자연어의 처리가 가능
    - 역색인 구조를 바탕으로 빠른 검색 속도 보장

- 엘라스틱서치와 관계형 데이터베이스 비교
    | **엘라스틱서치** | **관계형 데이터베이스** |
    | --- | --- |
    | 인덱스 index | 데이터베이스 database |
    | 샤드 shard | 파티션 partition |
    | 타입 type | 테이블 table |
    | 문서 document | 행 row |
    | 필드 field | 열 column |
    | 매핑 mapping | 스키마 schema |
    | Query DSL | SQL |

- 엘라스틱 서치는 기본적으로 HTTP를 통해 JSON형식의 RESTful API 이용

- 추가, 검색, 삭제, 수정 기능 비교
    | **엘라스틱서치에서 사용하는 HTTP 메서드** | **기능** | **데이터베이스 질의 문법** |
    | --- | --- | --- |
    | **GET** | 데이터 조회 | SELECT |
    | **PUT** | 데이터 생성 | INSERT |
    | **POST** | 인덱스 업데이트, 데이터 조회 | UPDATE, SELECT |
    | **DELETE** | 데이터 삭제 | DELETE |
    | **HEAD** | 인덱스 정보 확인, 특정 문서의 정보 유무 확인 | - |

## 1.2 검색 시스템과 엘라스틱 서치
### 1.2.1 엘라스틱서치가 강력한 이유
1. **오픈소스 검색엔진**
    - 아파치 재단의 루씬(Lucene)을 기반으로 개발된 오픈소스 검색엔진

2. **전문 검색**
    - 내용 전체를 색인해서 특정 단어가 포함된 문서를 검색하는 것
    - 다양한 기능별, 언어별 플러그인을 조합해 빠르게 검색

3. **통계분석**
    - 비정형 로그 데이터를 수집하고 한곳에 모아 통계 분석 가능
    - 엘라스틱서치와 키바나를 연결하면 실시간으로 쌓이는 로그 시각화 & 분석 가능

4. **스키마리스(Schemaless)**
    - 정형화되지 않은 다양한 형태의 문서도 자동으로 색인하고 검색

5. **RESTful API**
    - HTTP 기반의 RESTful API 지원, 요청
    - 응답에도 JSON 형식 사용 → 개발 언어, 운영체제, 시스템에 관계없이 이기종 플랫폼에서도 이용 가능

6. **멀티텐넌시(Multi-tenancy)**
    - 검색할 필드명만 같으면 여러 개의 인덱스 한번에 조회 가능 → 이를 이용해 멀티텐넌시 기능 제공

7. **Document-Oriented**
    - 여러 계층의 데이터를 JSON 형식의 구조화된 문서로 인덱스에 저장
    - 계층 구조로 문서도 한번의 쿼리로 쉽게 조회

8. **역색인(Inverted Index)** : 키워드를 통해 문서를 찾는 방식
    - 루씬 기반의 검색엔진 → 역색인 지원

9. **확장성과 가용성**
    - 엘라스틱서치를 분산 구성해 확장 → 대량의 문서를 효율적으로 처리
    - 분산 환경에서 데이터는 샤드(shard)라는 작은 단위로 나뉘어 제공 → 인덱스를 만들 때마다 샤드 수 조절 가능\
        ⇒ 데이터를 분산해서 빠르게 처리 가능
        
### 1.2.2 엘라스틱서치의 약점
1. **실시간이 아님 → 준 실시간**
    - 색인된 데이터는 1초 뒤 검색이 가능 → 내부적으로 커밋(commit)과 플러시(flush)같은 복잡한 과정을 거치기 때문

2. **트랜잭션과 롤백 기능 제공 X**
    - 최악의 경우 데이터 손실의 위험이 있음\
        → 시스템적으로 비용 소모가 큰 롤백(Rollback)과 트랜잭션(Transaction)을 지원하지 않기 때문\
        → 전체적인 성능 향상을 위해

3. **데이터의 업데이트 제공 X**
    - 엘라스틱서치는 업데이트 명령이 요청될 경우 기존 문서를 삭제하고 변경된 내용으로 새로운 문서를 생성하는 방식 사용\
        → 단순 업데이트에 비해 상대적으로 많은 비용 발생\
        ⇒ 불변적(Immutable)인 이점을 취할 수 있기 때문에 큰 단점은 아님


# 데이터 모델링
## 3.3 필드 데이터 타입
- 문자열 데이터 타입 : keyword, text
- 일반적인 데이터 타입 : date, long, double, integer, boolean, ip
- JSON 계층의 특성의 데이터 타입 : 객체, 중첩문
- 특수한 데이터 타입 : geo_point, geo_shape

### 3.3.1 Keyword 데이터 타입
- 키워드 형태로 사용할 데이터에 적합한 데이터 타입
- 별도의 분석기를 거치지 않고 원문 그대로 색인 → 특정 코드나 키워드 등 정형화된 콘텐츠에 주로 사용
- **검색 시 필터링되는 항목, 정렬이 필요한 항목, 집계(Aggregation)해야하는 항목**에 많이 사용
```jsx
PUT /movie_mapping/_mapping
{
	"properties": {
		"multiMovieNm": {
			"type": "keyword"
		}
	}	
}
```

### 3.3.2 Text 데이터 타입
- 색인 시 지정된 분석기가 칼럼의 데이터를 문자열 데이터로 인식하고 분석
- 기본값 : Standard Analyzer
- 영화의 제목이나 영화의 설명글과 같이 문장 형태의 데이터에 사용하기 적합
```jsx
PUT /movie_mapping/_mapping
{
	"properties": {
		"multiMovieNm": {
			"type": "text"
		}
	}	
}
```

### 3.3.3 Array 데이터 타입
- 문자열이나 숫자처럼 일반적인 값을 지정할 수 있지만 객체 형태로도 정의 가능
    - 저장되는 값은 모두 같은 타입으로만 구성해야함
```jsx
PUT /movie_mapping/_mapping
{
	"title" : "해리포터",
	"subtitleLang": ["ko", "en"]
}
```

### 3.3.4 Numeric 데이터 타입
- 여러 개 제공 → 데이터의 크기에 알맞은 타입을 제공함으로써 색인과 검색을 효율적으로 처리하기 위해서
    - long : 64비트 정수
    - integer : 32비트 정수
    - short : 16비트 정수
    - byte : 8비트 정수
    - double : 64비트 소수점
    - float : 32비트 소수점
    - half_float : 16비트 소수점
```jsx
PUT /movie_mapping/_mapping
{
	"properties": {
		"Year" : {
			"type": "integer"
		}
	}
}
```

### 3.3.5 Date 데이터 타입
- "date"
- JSON 포맷에서 문자열로 처리
- 기본 형식 : “yyyy-MM-ddTHH:mm:ssZ”

```jsx
PUT /movie_mapping/_mapping
{
	"properties": {
		"date": {
			"type": "date",
			"format": "yyyy-MM-dd""
		}
	}
}
```

### 3.3.6 Range 데이터 타입
- "showRange"
- 범위가 있는 데이터를 저장할 때 사용
- 범위의 시작과 끝만 정의
    - integer_range : 32비트 정수 범위
    - float_range : 32비트 실수 범위
    - long_range : 64비트 정수 범위
    - double_range : 64비트 실수 범위
    - date_range : 64비트 정수형태, 날짜 범위(밀리초)
    - ip_range : IPv4, IPv6
```jsx
PUt /movie_mapping/_mapping
{
	"properties": {
		"showRange": {
			"type": "date_range"	
		}
	}
}

PUT /movie_mapping/_doc
{
	"showRange": {
		"gte": "2025-01-01",
		"lte": "2025-12-31"
	}
}
```

### 3.3.7 Boolean 데이터 타입
- "check"
- 참과 거짓이라는 두 논리값을 가지는 데이터 타입
    - 참 : true, “true” / 거짓 : false, “false”

### 3.3.8 Geo-Point 데이터 타입
- "filmLocation"
- 위도, 경도 등 위치 정보를 담은 데이터 저장
- 위치기반 데이터를 색인하고 검색하는데 매우 유용
    - 위치 기반 쿼리를 이용해 반경 내 쿼리, 위치 기반 집계, 위치별 정렬 등을 사용할 수 있기 때문
```jsx
PUT /movie_mapping/_mapping
{
	"properties" :{
		"filmLocation": {
			"type": "geo_point"
		}
	}
}

PUT /movie_mapping/_doc
{
	"filmLocation": {
		"lat": 55,
		"lon": -1
	}
}
```

### 3.3.9 IP 데이터 타입
- "ipAdds"
- IP주소와 같은 데이터 저장 → IPv4, IPv6

### 3.3.10 Object 데이터 타입
- "companies"
- Object : 값으로 문서를 가지는 필드

### 3.3.11 Nested 데이터 타입
- "companies_nested"
- Object 객체 배열을 독립적으로 색인하고 질의하는 형태의 데이터타입
    - 필드 내에 Object 형식으로 JSON 포맷 표현 가능

## 3.4 엘라스틱서치 분석기
### 3.4.1 텍스트 분석 개요
1. 문서를 색인하기 전 해당 문서의 필드 타입이 무엇인지 확인
2. 텍스트 타입이면 분석기를 이용해 분석
3. 텍스트가 분석되면 개별 텀으로 나뉘어 형태소 형태로 분석
4. 해당 형태소는 특정 원칙에 의해 필터링되어 단어가 삭제/추가/수정
5. 역색인\
→ 언어별로 조금씩 다르게 동작 ⇒ 언어별 분석기 제공(커스텀 가능)

- 분석기의 기본값 : Standard Analyzer
```jsx
POST _analyze
{
	"analyzer": "standard",
	"text": "우리나라가 좋은나라, 대한민국 화이팅"
}

=> "우리나라가", "좋은나라", "대한민국", "화이팅"
```
### 3.4.2 역색인 구조
1. 모든 문서가 가지는 단어의 고유 단어 목록 - **토큰**
2. 해당 단어가 어떤 문서에 속해 있는지에 대한 정보 - **문서 번호**
3. 전체 문서에 각 단어가 몇 개 들어있는지에 대한 정보 - **텀의 위치**
4. 하나의 문서에 단어가 몇 번씩 출현했는지에 대한 빈도 - **텀의 빈도**
- 색인 : 역색인 파일을 만드는 것
    - 원문 자체 변경 X
    - 색인 파일에 들어갈 토큰만 변경되어 저장, 실제 문서 내용 변함X
- 분석 : 색인할 때 특정한 규칙과 흐름에 의해 텍스트를 변경하는 과정

### 3.4.3 분석기의 구조
1. **CHARACTER FILTER** : 문장을 특정한 규칙에 의해 수정
    - 문장을 분석하기 전 입력 텍스트에 대해 특정한 단어 변경
    - HTML과 같은 태그 제거

2. **TOKENIZER FILTER** : 수정한 문장을 개별 토큰으로 분리
    - 분석기를 구성할 때 하나만 사용 가능
    - 텍스트를 어떻게 나눌 것인지 정의
    
3. **TOKEN FILTER** : 개별 토큰을 특정한 규칙에 의해 변경
    - 토큰화된 단어를 하나씩 필터링해서 사용자가 원하는 토큰으로 변환
    - 불필요한 단어 제거, **동의어 사전**을 만들어 단어 추가, 영문 단어를 소문자로 변환 등

**3.4.3.1 분석기 사용법**
- 분석기를 이용한 분석
```jsx
POST _analyze
{
	"analyzer" : "standard",
	"text": "캐리비안의 해적"
}
```

- 필드를 이용한 분석
```jsx
POST /movie_analyzer/_analyze
{
	"field": "title",
	"text": "캐리비안의 해적"
}
```

- 색인과 검색 시 분석기를 각각 설정
    - 인덱스를 생성할 때 색인용과 검색용 분석기를 각각 정의 → 적용하고자 하는 필드에 원하는 분석기 지정

**3.4.3.2 대표적인 분석기**
1. **Standard Analyzer**
    - 공백 혹은 특수 기호를 기준으로 토큰을 분리하고 모든 문자를 소문자로 변경하는 토큰 필터 사용
    - 구성요소
        - Tokenizer : Standard Tokenizer
        - Token Filter : Standard Token Filter, Lower Case Token Filter
    - 옵션
        - **max_token_length** : 최대 토큰 길이를 초과하는 토큰이 보일 경우 해당 length간격으로 분할, 기본값 : 255자
        - **stopwords** : 사전에 정의된 불용어 사전 사용, 기본값 X
        - **stopwords_path** : 불용어 파일을 사용할 경우 서버 경로로 지정
    ```jsx
    POST _analyze
    {
    	"analyzer" : "standard",
    	"text": "Hello world!!!"
    }
    
    => [hello, world]
    ```
    
2. **Whitespace 분석기**
    - 공백 문자열을 기준으로 토큰 분리
    - 구성요소
        - Tokenizer : Whitespace Tokenizer
    ```jsx
    POST _analyze
    {
    	"analyzer": "whitespace",
    	"text": "Hello World!!!"
    }
    
    => [Hello, World]
    ```
    
3. **Keyword 분석기**
    - 전체 입력 문자열을 하나의 키워드로 처리
    ```jsx
    POST _analyze
    {
    	"analyzer": "keyword",
    	"text": "Hello World"
    }
    
    => [Hello World]
    ```
    
### 3.4.4 전처리 필터
- **HTML strip char 필터** : 문장에서 HTML을 제거하는 전처리 필터
    - 옵션 **escaped_tags** : 특정 태그만 삭제(남겨둘 태그 지정), 기본값 : 전부 삭제

### 3.4.5 토크나이저 필터
1. **Standard 토그나이저 :** 기호를 만나면 토큰을 나눔
    - 옵션 **max_token_length** : 최대 토큰 길이를 초과하는 경우 해당 간격으로 토큰 분할, 기본값 : 255자

2. **Whitespace 토크나이저 :** 공백을 만나면 텍스트 토큰화
    - 옵션 **max_token_length** : 최대 토큰 길이를 초과하는 경우 해당 간격으로 토큰 분할, 기본값 : 255자

3. **Ngram 토크나이저 :** 한 글자씩 토큰화
    - 특정 문자 지정 가능 → 지정된 문자의 목록 중 하나를 만날 때마다 단어를 자름
    - 옵션
        - **min_gram** : 적용할 문자의 최소 길이, 기본값 : 1
        - **max_gram** : 적용할 문자의 최대 길이 , 기본값 : 2
        - **token_chars** : 토큰에 포함할 문자열 지정
            - letter(문자)
            - digit(숫자)
            - whitespace(공백)
            - punctuation(구두점)
            - symbol(기호)
    ```jsx
    Harry Potter and the Chamber of Secrets
    
    => [Har, arr, rry, Pot, ott, tte, ter, and, the, Cha, ham, amb, mbe, ber, Sec, cr, cre, ret, ets]
    ```
    
4. **Edge Ngram 토크나이저** : 지정된 문자의 목록 중 하나를 만날 때마다 **시작 부분을 고정**시켜 단어를 자르는 방식
    - 옵션은 Ngram 토크나이저와 같음
    ```jsx
    Harry Potter and the Chamber of Secrets / min_gram : 2 / max_gram : 10
    
    => [Ha, Har, Harr, Harry, Po, Pot, Pott, Potte, Potter, ...]
    ```
    
5. **Keyword 토크나이저** : 텍스트를 하나의 토큰으로 만듬
    - 옵션 buffer_size : 텀을 버퍼로 읽어 들일 문자 수 지정, 기본값 : 256

### 3.4.6 토큰 필터
- 토크나이저에서 분리된 토큰들을 변형하거나 추가, 삭제할 때 사용
- 분리된 토큰은 배열 형태로 토큰 필터로 전달
- 독립적으로 사용 불가

1. **Ascii Folding 토큰 필터**
    - 아스키 코드에 해당하는 127개의 알파벳, 숫자, 기호에 해당하지 않는 경우 문자를 ASCII요소로 변경

2. **Lowercase 토큰 필터**
    - 토큰을 구성하는 전체 문자열을 **소문자로 변환**

3. **Uppercase 토큰 필터**
    - 전체 문자열을 **대문자로 변환**

4. **Stop 토큰 필터**
    - 불용어로 등록할 사전을 구축해서 사용하는 필터
    - 인덱스로 만들고 싶지 않거나 검색되지 않게 하고 싶은 단어를 등록해서 해당 단어에 대한 불용어 사전 구축
    - 옵션
        - **stopsords** : 불용어를 매핑에 직접 등록해서 사용
        - **stopwords_path** : 불용어 사전이 존재하는 경로 지정, config폴더에 생성
        - **ignore_case** : true로 지정할 경우 모든 단어를 소문자로 변경해서 저장, 기본값 : false

5. **Stemmer 토큰 필터**
    - 알고리즘을 사용해 토큰을 변경하는 필터
    - 옵션 **name** : english, light_english, minial_english, porter2, lovins 등 다른 나라 언어 사용 가능, 한국은 지원X

6. **Synonym 토큰 필터**
    - 동의어를 처리할 수 있는 필터
    - 옵션
        - **synonyms** : 동의어로 사용할 단어 등록
        - **synonyms_path** : 파일로 관리할 경우 경로 지정, config폴더에 생성

7. **Trim 토큰 필터**
    - 앞뒤 공백을 제거하는 토큰

### 3.4.7 동의어 사전
- 동의어 : 검색 기능을 풍부하게 할 수 있게 도와주는 도구 중 하나
    - 원문에 특정 단어가 존재하지 않더라도 색인 데이터를 토큰화해서 저장할 때 동의어나 유의어에 해당하는 단어를 함께 저장해서 검색이 가능해지게 하는 기술 ⇒ “Elasticsearch”라면 “엘라스틱서치”도 함께 저장

- 동의어 추가 방식
    1. 매핑 설정 정보에 미리 파라미터로 등록
    2. 특정 파일(동의어 사전)을 별도로 생성해서 관리

- 동의어 사전 만들기
    - 데이터 추가 방법
        1. **동의어 추가 :** 동의어를 추가할 때 쉼표(,)로 등록하는 방법
            ```jsx
            Elasticsearch, 엘라스틱서치
            ```
            
        2. **동의어 치환** : 특정 단어를 어떤 단어로 변경할 때 사용
            - 원본 토큰 제거, 변경될 새로운 토큰 추가
            ```jsx
            Harry => 해리
            ```