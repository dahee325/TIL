# 9-1 텍스트를 위한 인공신경망
## 순차 데이터
- 텍스트나 시계열 데이터와 같이 순서에 의미가 있는 데이터 => 형태를 유지시키는게 중요

### 피드포워드 신경망
- 입력 데이터의 흐름이 앞으로만 전달되는 신경망

## 순환 신경망(RNN, recurrent neural network)
- `keras.layers.simpleRNN()`
- 완전 연결 신경망에 이전 데이터의 처리 흐름을 순환하는 고리 하나만 추가된 신경망
- 뉴런의 출력이 다시 자기 자신으로 전달 => 어떤 샘플을 처리할 때 바로 이전에 사용했던 데이터를 재사용
- 타임스텝(timestep) : 샘플을 처리하는 한 단계
- 셀(cell) : 층
- 은닉 상태(hidden state) : 셀의 출력
- 은닉층의 활성화 함수 : 하이퍼볼릭 탄젠트 함수 tanh^2 => -1 ~ 1 사이

# 9-2

# 9-3
## LSTM
- Long Short-Term Memory, 단기 기억을 오래 기억하기위해 고안
- 순환되는 상태가 2개 : 은닉 상태, 셀 상태
- 셀 상태 : 다음 층으로 전달되지 않고 LSTM 셀에서 순환만 되는 값
## GRU
- Gated Recurrent Unit, LSTM을 간소화한 버전